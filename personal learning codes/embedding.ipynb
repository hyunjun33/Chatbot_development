{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c5d47c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Komoran\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc74fb64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['오늘', '날씨', '구름']\n"
     ]
    }
   ],
   "source": [
    "komoran = Komoran()\n",
    "text = \"오늘 날씨는 구름이 많아요.\"\n",
    "\n",
    "# 명사만 추출\n",
    "nouns = komoran.nouns(text)\n",
    "print(nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48e2edfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'오늘': 0, '날씨': 1, '구름': 2}\n"
     ]
    }
   ],
   "source": [
    "# 단어 사전 구축 및 단어별 인덱스 부여\n",
    "dics = {}\n",
    "for word in nouns:\n",
    "    if word not in dics.keys():\n",
    "        dics[word] = len(dics)\n",
    "print(dics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ef54ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# 원-핫 인코딩\n",
    "nb_classes = len(dics)\n",
    "targets = list(dics.values())\n",
    "one_hot_targets = np.eye(nb_classes)[targets]\n",
    "print(one_hot_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0dd62974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec model 학습\n",
    "from gensim.models import Word2Vec\n",
    "from konlpy.tag import Komoran\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5cbeb4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) 말뭉치 데이터 읽기 시작\n",
      "200000\n",
      "1) 말뭉치 데이터 읽기 완료:  1.9889864921569824\n",
      "2) 형태소에서 명사만 추출 시작\n",
      "2) 형태소에서 명사만 추출 완료:  89.36491060256958\n",
      "3) Word2Vec 모델 학습 시작\n",
      "3) Word2Vec 모델 학습 완료:  108.69314241409302\n",
      "4) 학습된 모델 저장 시작\n",
      "4) 학습된 모델 저장 완료:  109.22473001480103\n",
      "corpus_count:  200000\n",
      "corpus_total_words:  1076896\n"
     ]
    }
   ],
   "source": [
    "# 네이버 영화 리뷰 베이터 읽어옴\n",
    "def read_review_data(filename):\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = [line.split(\"\\t\") for line in f.read().splitlines()]\n",
    "        data = data[1:]\n",
    "    return data\n",
    "\n",
    "# 학습 시간 측정 시작\n",
    "start = time.time()\n",
    "\n",
    "# 리뷰 파일 읽어오기\n",
    "print(\"1) 말뭉치 데이터 읽기 시작\")\n",
    "review_data = read_review_data(\"./ratings.txt\")\n",
    "print(len(review_data)) # 리뷰 데이터 전체 개수\n",
    "print(\"1) 말뭉치 데이터 읽기 완료: \", time.time() - start)\n",
    "\n",
    "# 문장 단위로 명사만 추출해서 학습 입력 데이터로 만듦\n",
    "print(\"2) 형태소에서 명사만 추출 시작\")\n",
    "komoran = Komoran()\n",
    "docs = [komoran.nouns(sentence[1]) for sentence in review_data]\n",
    "print(\"2) 형태소에서 명사만 추출 완료: \", time.time() - start)\n",
    "\n",
    "# Word2Vec 모델 학습\n",
    "print(\"3) Word2Vec 모델 학습 시작\")\n",
    "model = Word2Vec(sentences=docs, vector_size=200, window=4, hs=1, min_count=2, sg=1)\n",
    "print(\"3) Word2Vec 모델 학습 완료: \", time.time() - start)\n",
    "\n",
    "# 모델 저장\n",
    "print(\"4) 학습된 모델 저장 시작\")\n",
    "model.save(\"nvmc.model\")\n",
    "print(\"4) 학습된 모델 저장 완료: \", time.time() - start)\n",
    "\n",
    "# 학습된 말뭉치 수, 코퍼스 내 전체 단어 수\n",
    "print(\"corpus_count: \", model.corpus_count)\n",
    "print(\"corpus_total_words: \", model.corpus_total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bed061a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus_total_words:  1076896\n",
      "사랑:  [-0.03685663 -0.42167908  0.02685775 -0.14264534 -0.1700458  -0.3156721\n",
      " -0.01655827  0.3312561   0.2058018   0.1431381  -0.11901294 -0.15261705\n",
      " -0.0431291   0.08504339 -0.30478635  0.09490284 -0.06405049 -0.09885142\n",
      " -0.28437138 -0.26277325  0.1725525   0.14996408 -0.26925272  0.14353988\n",
      " -0.18371096  0.05570001  0.27569112 -0.05814886 -0.23663864 -0.0350089\n",
      "  0.15608512  0.17034128 -0.0414695  -0.26766452  0.1963109   0.22288959\n",
      " -0.14951417 -0.127062   -0.0843439  -0.14024146 -0.18359353  0.19068392\n",
      " -0.04238747  0.08582901  0.12229525  0.24200384 -0.25764784 -0.02717914\n",
      "  0.47539738  0.3758161   0.16036971 -0.03842648 -0.06018594 -0.13770464\n",
      "  0.47064006 -0.0639108   0.3585746  -0.31894436 -0.1469196   0.02211447\n",
      " -0.11160678  0.02617247  0.04307424  0.11127619  0.13044347  0.02376742\n",
      " -0.5331304  -0.04104411  0.24096565  0.26641455  0.01180822 -0.09173312\n",
      "  0.11698808 -0.03632953  0.01010222 -0.14943013  0.31790432 -0.14388713\n",
      " -0.39879224  0.12207679 -0.04695786 -0.16483499  0.04967535  0.5171003\n",
      " -0.26688665 -0.18484513 -0.28072646 -0.09420939 -0.26872146  0.1421565\n",
      "  0.08320075  0.49831823  0.3061625  -0.21987364  0.2820718   0.10163246\n",
      "  0.2101381  -0.20212713  0.21121436 -0.01049749 -0.06002329  0.4828005\n",
      "  0.25503784  0.17981707 -0.06591369 -0.16300622  0.04548747  0.27677774\n",
      "  0.15967938 -0.49132454  0.0849657  -0.16367151  0.12058949 -0.01522998\n",
      "  0.25717628 -0.25009763 -0.07193241  0.00803803  0.36372146  0.07402095\n",
      "  0.31742972 -0.11372926  0.11566543 -0.16519372  0.22798371  0.21049331\n",
      " -0.20684363  0.31318724 -0.09691034 -0.20294996  0.02150842  0.07728142\n",
      " -0.05888945  0.18803808  0.3354638   0.32051802  0.38824046 -0.04020726\n",
      " -0.20488146 -0.04160812  0.14099398 -0.29914084 -0.25910348 -0.15452828\n",
      " -0.0267345   0.03004698 -0.26932642 -0.00116291 -0.04519315  0.16633567\n",
      "  0.07611444 -0.23168775  0.13405865  0.03518774 -0.23428203  0.02008156\n",
      "  0.05196832  0.17915826  0.07102392 -0.14373668 -0.13894539 -0.3173445\n",
      " -0.07965077 -0.18248262 -0.260299    0.05061001 -0.15441236 -0.10735062\n",
      "  0.16446589 -0.08439127 -0.45104486 -0.04184784  0.11387357 -0.12674136\n",
      " -0.1623779   0.01513257 -0.10930294 -0.26226518  0.20549785 -0.17780969\n",
      " -0.16389987 -0.06077901 -0.091089   -0.32315615 -0.18533854 -0.08277623\n",
      " -0.01337195  0.04570724  0.20748332  0.01961064  0.10846857 -0.31060743\n",
      "  0.13391507 -0.11218731  0.18273629  0.21753682 -0.2104687  -0.06755055\n",
      "  0.01742838  0.19593441]\n",
      "일요일 = 월요일\t 0.67396516\n",
      "안성기 = 배우\t 0.5532146\n",
      "대기업 = 삼성\t 0.5166117\n",
      "일요일 != 삼성\t 0.2146177\n",
      "히어로 != 삼성\t 0.1834039\n"
     ]
    }
   ],
   "source": [
    "# Word2Vec model 활용\n",
    "# 모델 불러오기\n",
    "model = Word2Vec.load(\"nvmc.model\")\n",
    "print(\"corpus_total_words: \", model.corpus_total_words)\n",
    "\n",
    "# \"사랑\"이란 단어로 생성한 단어 임베딩 벡터\n",
    "print(\"사랑: \", model.wv[\"사랑\"])\n",
    "\n",
    "# 단어 유사도 계산\n",
    "print(\"일요일 = 월요일\\t\", model.wv.similarity(w1=\"일요일\", w2=\"월요일\"))\n",
    "print(\"안성기 = 배우\\t\", model.wv.similarity(w1=\"안성기\", w2=\"배우\"))\n",
    "print(\"대기업 = 삼성\\t\", model.wv.similarity(w1=\"대기업\", w2=\"삼성\"))\n",
    "print(\"일요일 != 삼성\\t\", model.wv.similarity(w1=\"일요일\", w2=\"삼성\"))\n",
    "print(\"히어로 != 삼성\\t\", model.wv.similarity(w1=\"히어로\", w2=\"삼성\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4dfffc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('씨야', 0.7206252217292786), ('정재영', 0.711334764957428), ('김갑수', 0.7031294703483582), ('장미희', 0.6973748803138733), ('고준희', 0.6943286061286926)]\n",
      "[('나니아 연대기', 0.6817585825920105), ('캐리비안의 해적', 0.6745085120201111), ('더 울버린', 0.6623805165290833), ('X맨', 0.6457725763320923), ('기사단', 0.6443246006965637)]\n"
     ]
    }
   ],
   "source": [
    "# 가장 유사한 단어 추출\n",
    "print(model.wv.most_similar(\"안성기\", topn=5))\n",
    "print(model.wv.most_similar(\"시리즈\", topn=5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
